{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Deep Learning - PART1 TF2 Basics >\n",
    "# Ch 1. Workshop - TensorFlow 2.0 Installation & Testing\n",
    "\n",
    "2023/06/27\n",
    "\n",
    "--------------------------------------\n",
    "### **<< `Installation of TF 2.0 with Anaconda3` >>**\n",
    "+ ####  First, install `Anaconda 3 for Windows/macOS/Linux` from  https://www.anaconda.com/distribution/\n",
    "\n",
    "+ #### Next, run `TensorFlow 2 (for CPU)` Setup on `Anaconda Prompt` :\n",
    "> ####           `pip install tensorflow`\n",
    "--------------------------------------\n",
    "\n",
    "### [ Reference ]:\n",
    "+ TensorFlow.org, **\"Install TensorFlow 2\"** https://www.tensorflow.org/install\n",
    "\n",
    "+ TensorFlow.org, **\"Get Started with TensorFlow\"** https://www.tensorflow.org/tutorials/#get-started-with-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Content ]\n",
    "- [1. Testing TF 2.0](#TF2)\n",
    "- [2. How to run TensorFlow 1.x code on TF 2.0](#RunTF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TF2'></a>\n",
    "## 1. Testing TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <img src=\"1.jpg\" width=\"1200\" height=\"700\">\n",
    "> <img src=\"2.jpg\" width=\"1200\" height=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3766 - accuracy: 0.8883\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1793 - accuracy: 0.9475\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1382 - accuracy: 0.9602\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1181 - accuracy: 0.9657\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1058 - accuracy: 0.9676\n",
      "313/313 - 1s - loss: 0.0800 - accuracy: 0.9759 - 574ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0799984261393547, 0.9758999943733215]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# The following code is for testing TensorFlow 2.0 setup: \n",
    "#\n",
    "#  [Ref]: \"Get Started with TensorFlow\" \n",
    "#  https://www.tensorflow.org/tutorials/#get-started-with-tensorflow\n",
    "# ---------------------------------------------\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#Sequential的意思是按照次序放\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), #把所有的影像拉平(Flatten)\n",
    "  tf.keras.layers.Dense(128, activation='relu'), #前一層的hidden layer和下一層hidden layer節點之間全部連結\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),  \n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "#compile : back propagation\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test, verbose=2) # verbose: Verbosity mode. 0=silent, 1=progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "<a id='RunTF1'></a>\n",
    "## 2. How to run TensorFlow 1.x code on TF 2.0\n",
    "+ ### It is still possible to run 1.X code, unmodified (except for contrib), in TensorFlow 2.0:\n",
    "\n",
    "> ####  **`import tensorflow.compat.v1 as tf`**  \n",
    "> ####  **`tf.disable_v2_behavior()`**\n",
    "\n",
    "> **[ NOTE ]:**\n",
    "+ **More detailed information regarding \"`Migrate your TensorFlow 1 code to TensorFlow 2`\" can be found here:** https://www.tensorflow.org/guide/migrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "### The following code is adopted for testing TensorFlow 2.0 setup from the reference below: \n",
    "\n",
    "+ Tom Hope, Yehezkel S. Resheff, and Itay Lieder, \"**Learning TensorFlow : A Guide to Building Deep Learning Systems**,\" Chapter 2 & 4, O'Reilly, 2017. https://goo.gl/iEmehh\n",
    "+ Download the code from GitHub : https://github.com/gigwegbe/Learning-TensorFlow\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST dataset (from TensorFlow 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.array([x_train[i].flatten() for i in range(len(x_train))])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array([x_test[i].flatten() for i in range(len(x_test))])\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(vec, vals=10):\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = one_hot(y_train)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = one_hot(y_test)\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Computation Graph on TF 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each Input Image, X, with 28*28 (= 784) pixels\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# y_true : the training labeled dataset \n",
    "y_true = tf.placeholder(tf.float32,[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Weights & Biases for Nodes in All Hidden Layers \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1) \n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape) \n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Fully-Connected Deep Network\n",
    "def full_layer(inputs, size):\n",
    "    in_size = int(inputs.get_shape()[1]) \n",
    "    W = weight_variable([in_size, size]) \n",
    "    b = bias_variable([size])\n",
    "    return tf.add(tf.matmul(inputs, W), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\appcl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)  \n",
    "\n",
    "# < Hidden Layer 1 >\n",
    "layer_1_drop = tf.nn.dropout(X, keep_prob=keep_prob)\n",
    "#   Activation Function : ReLU\n",
    "layer_1_Outputs = tf.nn.relu(full_layer(layer_1_drop, 256))\n",
    "\n",
    "# < Hidden Layer 2 >\n",
    "layer_2_drop = tf.nn.dropout(layer_1_Outputs, keep_prob=keep_prob)\n",
    "#   Activation Function : ReLU\n",
    "layer_2_Outputs = tf.nn.relu(full_layer(layer_2_drop, 128))  \n",
    "\n",
    "# < Output Layer >\n",
    "output_drop = tf.nn.dropout(layer_2_Outputs, keep_prob=keep_prob)\n",
    "# Without Activation Function\n",
    "y_pred = full_layer(output_drop, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\appcl\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "gd_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching the Computation Graph on TF 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(i, images, labels, batch_size):\n",
    "    i_start = (i * batch_size) % len(images)\n",
    "    x, y = images[i_start : i_start+batch_size], labels[i_start : i_start+batch_size]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 : Loss = 0.2138, Accuracy = 0.930\n",
      "Step 2000 : Loss = 0.1174, Accuracy = 0.970\n",
      "Step 3000 : Loss = 0.1400, Accuracy = 0.990\n",
      "Step 4000 : Loss = 0.0831, Accuracy = 0.990\n",
      "Step 5000 : Loss = 0.0749, Accuracy = 0.980\n",
      "Step 6000 : Loss = 0.0970, Accuracy = 0.990\n",
      "Step 7000 : Loss = 0.0590, Accuracy = 0.990\n",
      "Step 8000 : Loss = 0.0534, Accuracy = 0.980\n",
      "\n",
      " Computing the test accuracy ...  \n",
      " [ Test  Accuracy ] : 0.9642000198364258\n",
      " [ Test Loss Score ] : 0.119362473487854\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 8000\n",
    "MINIBATCH_SIZE = 100\n",
    "Display_Step = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(NUM_STEPS):\n",
    "        batch_xs, batch_ys = next_batch(i, x_train, y_train, MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict ={X: batch_xs, \n",
    "                                      y_true: batch_ys,\n",
    "                                      keep_prob: 0.5})\n",
    "        \n",
    "        if (i+1) % Display_Step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss_temp, accu_temp = sess.run([cross_entropy, accuracy], \n",
    "                                            feed_dict={X: batch_xs, \n",
    "                                                       y_true: batch_ys,\n",
    "                                                       keep_prob: 1.0})\n",
    "            print(\"Step \" + str(i+1).rjust(4) + \\\n",
    "                  \" : Loss = \" + \"{:.4f}\".format(loss_temp) + \\\n",
    "                  \", Accuracy = \" + \"{:.3f}\".format(accu_temp))\n",
    "\n",
    "    print(\"\\n Computing the test accuracy ... \", end = \" \")\n",
    "    \n",
    "    ##  ------------------------------------------------------------------\n",
    "    ##  Split the test procedure into 10 blocks of 1,000 images each. \n",
    "    ##  Doing this is important mostly for much larger datasets.\n",
    "    ##  ------------------------------------------------------------------\n",
    "    ##  mnist.test.images.shape : (10000, 784)\n",
    "    X_test = x_test.reshape(10, 1000, 784) \n",
    "    ##  mnist.test.labels.shape : (10000, 10)\n",
    "    Y_test = y_test.reshape(10, 1000, 10)   \n",
    "    \n",
    "    test_loss = np.mean([sess.run(cross_entropy,\n",
    "                                  feed_dict={X: X_test[i], \n",
    "                                             y_true: Y_test[i], \n",
    "                                             keep_prob: 1.0}) \n",
    "                                  for i in range(10)])\n",
    "    test_accu = np.mean([sess.run(accuracy,\n",
    "                                  feed_dict={X: X_test[i], \n",
    "                                             y_true: Y_test[i], \n",
    "                                             keep_prob: 1.0}) \n",
    "                                  for i in range(10)])\n",
    "    print(\"\\n [ Test  Accuracy ] : {}\".format(test_accu) +\n",
    "      \"\\n [ Test Loss Score ] : {}\".format(test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
